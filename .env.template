# specify the ASR、LLM and TTS server to use
# options: OPENAI, GEMINI, TENCENT, VOLCENGINE, WHISPER, VOSK
ASR_SERVER=OPENAI 

# options: OPENAI, GEMINI, VOLCENGINE, OLLAMA
LLM_SERVER=OPENAI 

# options: OPENAI, GEMINI, TENCENT, VOLCENGINE, PIPER
TTS_SERVER=OPENAI

# specify the image generation server to use, the generated images will be saved in the data/images folder
# options: OPENAI, GEMINI, VOLCENGINE
IMAGE_GENERATION_SERVER=OPENAI

# specify the chat history reset time in seconds, default is 5 minutes (300 seconds)
# CHAT_HISTORY_RESET_TIME=300

# if you want to clean the data folder on each start, set the following environment variable to true
# CLEAN_DATA_FOLDER_ON_START=true

# enable or disable thinking of LLM
# if you are using ollama as LLM server, please confirm that the model supports thinking before enabling this option
# otherwise the ollama will return a 400 error
ENABLE_THINKING=true


## Tencent Cloud ASR and TTS
# if you are using tencent cloud as ASR or TTS server, please set the following environment variables
TENCENT_SECRET_ID=YourSecretId
TENCENT_SECRET_KEY=YourSecretKey
# endpoint is optional, default is asr.tencentcloudapi.com for ASR and tts.tencentcloudapi.com for TTS
# TENCENT_ASR_ENDPOINT=asr.tencentcloudapi.com
# TENCENT_TTS_ENDPOINT=tts.tencentcloudapi.com

## ByteDance VolcEngine ASR and TTS

# if you are using volcengine as ASR or TTS server, please set the following environment variables
# VOLCENGINE_APP_ID=volcengine_app_id
VOLCENGINE_ACCESS_TOKEN=volcengine_access_token

# You can choose different voice types and LLM models, please refer to the official documentation for more details:
# https://www.volcengine.com/docs/6561/1257544
# VOLCENGINE_VOICE_TYPE=zh_female_wanwanxiaohe_moon_bigtts

## ByteDance Doubao LLM
# if you are using volcengine as LLM server, please set the following environment variables
VOLCENGINE_DOUBAO_ACCESS_TOKEN=volcengine_doubao_access_token

# the default model is doubao-1-5-lite-16k-250115, you can also choose other models
# VOLCENGINE_DOUBAO_LLM_MODEL=doubao-1-5-lite-32k-250115
# for image generation, the default model is doubao-seedream-3-0-t2i-250415, you can also choose other models
# VOLCENGINE_DOUBAO_IMAGE_MODEL=doubao-seedream-3-0-t2i-250415

## Google Gemini
# if you are using google gemini as ASR / LLM / TTS / IMAGE_GENERATION server, please set the following environment variables
# Google Cloud has 300$ free credit for new users, you can use it to try the gemini api
# get your API key from https://console.cloud.google.com/apis/credentials, and make sure to enable the Generative Language API for your project
# also ensure the API key has the permission to access the Generative Language API
GEMINI_API_KEY=your_api_key
# the default model is gemini-1.5-flash (for ASR and LLM), you can also choose other models
# GEMINI_MODEL=gemini-1.5-flash
# for TTS, the default voice is "gemini-2.5-pro-preview-tts", you can also choose other voices, please refer to: https://ai.google.dev/gemini-api/docs/speech-generation
# GEMINI_TTS_MODEL=gemini-2.5-flash-preview-tts
# the default speaker is "Callirrhoe", you can also choose other speakers, please refer to:https://ai.google.dev/gemini-api/docs/speech-generation#voices
# GEMINI_TTS_SPEAKER=Callirrhoe
# the default language code is "en-US", you can also choose other language codes, please refer to https://ai.google.dev/gemini-api/docs/speech-generation#languages
# GEMINI_TTS_LANGUAGE_CODE=en-US

## Gemini Image Generation
# for image generation, the default model is "gemini-2.5-flash-image", you can also choose other models, please refer to: https://ai.google.dev/gemini-api/docs/image-generation
GEMINI_IMAGE_MODEL=gemini-2.5-flash-image

## OpenAI
# if you are using openai as ASR、TTS or LLM server, please set the following environment variables
OPENAI_API_KEY=openai_api_key
# the default model is gpt-4o, you can also choose other models
# OPENAI_LLM_MODEL=gpt-4o
# if you are using other openai compatible api server, please set the following environment variables
# OPENAI_API_BASE_URL=https://api.openai.com/v2
# if you are using openai as image generation server, please specify the generation model below. The default model is "dall-e-3"
# if you want to use "gpt-image-1", your organization need to be verified by openai first.
# Document link: https://platform.openai.com/docs/guides/image-generation
OPENAI_IMAGE_MODEL=dall-e-3

## Ollama
# if you are using ollama as LLM server, please set the following environment variables
OLLAMA_ENDPOINT=http://localhost:11434
# the default model is deepseek-r1:1.5b, you can also choose other models, please refer to: https://ollama.com/library
# OLLAMA_MODEL=deepseek-r1:1.5b
# if you want to enable tools for ollama, uncomment the following line (make sure the model supports tools, otherwise it will return a 400 error):
# OLLAMA_ENABLE_TOOLS=true
# if the ollama server is running on the same device, you can choose to serve ollama automatically when starting the chatbot, uncomment the following line:
# SERVE_OLLAMA=true

## Proxy Settings
# proxy settings for all cloud api request, uncomment the following lines if you need to use a proxy to access the internet
# usually you only need to set HTTPS_PROXY
# HTTPS_PROXY=https://your_https_proxy
# HTTP_PROXY=http://your_http_proxy
# ALL_PROXY=socks5://your_socks_proxy

## Custom System Prompt
# you can set a custom system prompt for LLM, please uncomment the following line and set your own prompt
# SYSTEM_PROMPT="You are a happy girl and also a helpful assistant. Answer the question quickly in less than 5 sentences, also with a sense of humor."

## Piper TTS
# if you are using piper as TTS server, please set the following environment variables
# Piper is an open-source TTS engine that can run locally on your device
# You can download Piper binaries for RPi from: https://github.com/OHF-Voice/piper1-gpl/blob/387ca06bfd0e7557c6d0d54ce34d36e7bb28389a/docs/CLI.md
# Voice models can be found at: https://rhasspy.github.io/piper-samples/
PIPER_BINARY_PATH=/path/to/piper-binary
PIPER_MODEL_PATH=/path/to/piper/voice/model.onnx

## Vosk ASR
# if you are using vosk as ASR server, please set the following environment variables
# Vosk is an open-source ASR engine that can run locally on your device
# You can download Vosk binaries and models from: https://alphacephei.com/vosk/models
# unzip the model to a folder and set the path below
VOSK_MODEL_PATH=/path/to/vosk/model

## Whisper ASR
# if you are using whisper as ASR server, please set the following environment variables
# Whisper is an open-source ASR engine that can run locally on your device
# https://github.com/openai/whisper
# the default model size is tiny, you can also choose other model sizes: tiny, base, small, medium, large. The tiny model will take ~1GB of VRAM
WHISPER_MODEL_SIZE=tiny
# the default language is English, if you leave it empty, whisper will try to detect the language automatically
# WHISPER_LANGUAGE=English

## Audio devices (ALSA)
# Set these to force Bluetooth headset devices; otherwise system default is used
# Example (PipeWire/Pulse default):
# AUDIO_OUTPUT_DEVICE=default
# AUDIO_INPUT_DEVICE=default
# Example (BlueALSA A2DP out / HSP mic):
# AUDIO_OUTPUT_DEVICE=bluealsa:DEV=XX:XX:XX:XX:XX:XX,PROFILE=a2dp
# AUDIO_INPUT_DEVICE=bluealsa:DEV=XX:XX:XX:XX:XX:XX,PROFILE=sco
TELEGRAM_BOT_TOKEN=123456789:ABCdefGHIjklMNOpqrsTUVwxyz1234567890